
# @package _global_
defaults:
  - /experiment/owt/base.yaml
  - override /model: gpt2
  - override /model/gpt2model: gpt2-small

datamodule:
  batch_size: 8  # Per GPU

train:
  optimizer:
    lr: 1.5e-4

expt_name: 10-20-attn=tk-repo=2-n=768-model=gpt2-small-pin=F-sync-F-v3
name: ${.expt_name}

model:
  _target_: tktrainer.models.gpt.GPTLMHeadModel
  config:
    mha_type: "tk"


