
# @package _global_
defaults:
  - /experiment/owt/gpt2s.yaml
  - override /model/gpt2model: gpt2-medium

datamodule:
  batch_size: 8  # Per GPU

train:
  optimizer:
    lr: 1.5e-4

expt_name: 10-19-attn=tk-repo=2-n=768-model=gpt2-medium-pinned=false
name: ${.expt_name}

model:
  config:
    _target_: "tktrainer.transformers.GPT2Config"
    mha_type: "tk"


