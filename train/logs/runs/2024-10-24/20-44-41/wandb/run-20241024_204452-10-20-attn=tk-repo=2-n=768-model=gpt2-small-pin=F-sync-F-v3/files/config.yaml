wandb_version: 1

_wandb:
  desc: null
  value:
    code_path: code/train/run.py
    python_version: 3.12.5
    cli_version: 0.16.2
    framework: huggingface
    huggingface_version: 4.46.0
    is_jupyter_run: false
    is_kaggle_kernel: false
    start_time: 1729827893.006401
    t:
      1:
      - 1
      - 9
      - 11
      - 41
      - 49
      - 50
      - 51
      - 55
      - 71
      2:
      - 1
      - 9
      - 11
      - 41
      - 49
      - 50
      - 51
      - 55
      - 71
      3:
      - 5
      - 7
      - 13
      - 14
      - 23
      4: 3.12.5
      5: 0.16.2
      6: 4.46.0
      8:
      - 5
      13: linux-x86_64
    m:
    - 1: trainer/global_step
      6:
      - 3
name:
  desc: null
  value: 10-20-attn=tk-repo=2-n=768-model=gpt2-small-pin=F-sync-F-v3
seed:
  desc: null
  value: 1111
resume:
  desc: null
  value: false
data_dir:
  desc: null
  value: /home/rahul/simran/based/train/data/
work_dir:
  desc: null
  value: /home/rahul/simran/based/train
expt_name:
  desc: null
  value: 10-20-attn=tk-repo=2-n=768-model=gpt2-small-pin=F-sync-F-v3
default_mode:
  desc: null
  value: true
print_config:
  desc: null
  value: true
task/_target_:
  desc: null
  value: train.tasks.seq.SequenceLMModel
train/gpu_mem:
  desc: null
  value: 82
datamodule/ddp:
  desc: null
  value: false
model/_target_:
  desc: null
  value: flash_attn.models.gpt.GPTLMHeadModel
ignore_warnings:
  desc: null
  value: true
logger/wandb/id:
  desc: null
  value: 10-20-attn=tk-repo=2-n=768-model=gpt2-small-pin=F-sync-F-v3
trainer/devices:
  desc: null
  value: 1
eval/log_on_step:
  desc: null
  value: true
trainer/_target_:
  desc: null
  value: pytorch_lightning.Trainer
trainer/strategy:
  desc: null
  value: null
logger/wandb/mode:
  desc: null
  value: online
logger/wandb/name:
  desc: null
  value: 10-20-attn=tk-repo=2-n=768-model=gpt2-small-pin=F-sync-F-v3
logger/wandb/tags:
  desc: null
  value: []
model/_recursive_:
  desc: null
  value: true
trainer/max_steps:
  desc: null
  value: 400000
trainer/num_nodes:
  desc: null
  value: 1
trainer/precision:
  desc: null
  value: 16
datamodule/add_eos:
  desc: null
  value: true
datamodule/shuffle:
  desc: null
  value: true
logger/wandb/group:
  desc: null
  value: ''
model/params_total:
  desc: null
  value: 124243200
train/optimizer/lr:
  desc: null
  value: 0.00015
trainer/max_epochs:
  desc: null
  value: 1000
trainer/min_epochs:
  desc: null
  value: 1
datamodule/_target_:
  desc: null
  value: train.datamodules.language_modeling_hf.LMDataModule
logger/wandb/prefix:
  desc: null
  value: ''
model/config/n_embd:
  desc: null
  value: 768
model/config/n_head:
  desc: null
  value: 12
test_after_training:
  desc: null
  value: true
trainer/accelerator:
  desc: null
  value: gpu
datamodule/cache_dir:
  desc: null
  value: /scratch/openwebtext/cache
datamodule/val_ratio:
  desc: null
  value: 0.0005
logger/wandb/project:
  desc: null
  value: based
model/config/n_layer:
  desc: null
  value: 12
datamodule/batch_size:
  desc: null
  value: 8
datamodule/max_length:
  desc: null
  value: 768
datamodule/pin_memory:
  desc: null
  value: true
logger/wandb/_target_:
  desc: null
  value: pytorch_lightning.loggers.wandb.WandbLogger
logger/wandb/job_type:
  desc: null
  value: train
logger/wandb/save_dir:
  desc: null
  value: .
model/config/_target_:
  desc: null
  value: transformers.GPT2Config
model/config/mha_type:
  desc: null
  value: tk
datamodule/num_workers:
  desc: null
  value: 32
logger/wandb/log_model:
  desc: null
  value: false
model/params_trainable:
  desc: null
  value: 124243200
train/loss_fn/_target_:
  desc: null
  value: flash_attn.losses.cross_entropy.CrossEntropyLoss
datamodule/dataset_name:
  desc: null
  value: openwebtext
train/global_batch_size:
  desc: null
  value: 512
callbacks/early_stopping:
  desc: null
  value: null
model/config/n_positions:
  desc: null
  value: 768
train/optimizer/_target_:
  desc: null
  value: torch.optim.AdamW
train/scheduler/_target_:
  desc: null
  value: transformers.get_linear_schedule_with_warmup
datamodule/fault_tolerant:
  desc: null
  value: true
datamodule/tokenizer_name:
  desc: null
  value: gpt2
datamodule/val_split_seed:
  desc: null
  value: 2357
eval/metrics/ppl/_target_:
  desc: null
  value: train.metrics.perplexity.Perplexity
trainer/gradient_clip_val:
  desc: null
  value: 1.0
datamodule/batch_size_eval:
  desc: null
  value: 8
model/params_not_trainable:
  desc: null
  value: 0
trainer/val_check_interval:
  desc: null
  value: 64000
train/optimizer/weight_decay:
  desc: null
  value: 0.1
callbacks/params_log/_target_:
  desc: null
  value: train.callbacks.params_log.ParamsLog
datamodule/dataset_config_name:
  desc: null
  value: null
train/loss_fn/inplace_backward:
  desc: null
  value: true
callbacks/gpu_affinity/_target_:
  desc: null
  value: train.callbacks.gpu_affinity.GpuAffinity
callbacks/model_checkpoint/mode:
  desc: null
  value: min
callbacks/norm_monitor/_target_:
  desc: null
  value: train.callbacks.norm_monitor.NormMonitor
trainer/accumulate_grad_batches:
  desc: null
  value: 64
trainer/check_val_every_n_epoch:
  desc: null
  value: null
callbacks/speed_monitor/_target_:
  desc: null
  value: train.callbacks.speed_monitor.SpeedMonitor
eval/metrics/num-tokens/_target_:
  desc: null
  value: train.metrics.num_tokens.NumTokens
train/scheduler/num_warmup_steps:
  desc: null
  value: 4000.0
callbacks/model_checkpoint/dirpath:
  desc: null
  value: /home/rahul/simran/based/train/checkpoints/10-20-attn=tk-repo=2-n=768-model=gpt2-small-pin=F-sync-F-v3
callbacks/model_checkpoint/monitor:
  desc: null
  value: val/loss
callbacks/model_checkpoint/verbose:
  desc: null
  value: false
callbacks/speed_monitor/epoch_time:
  desc: null
  value: true
train/scheduler/num_training_steps:
  desc: null
  value: 400000
callbacks/model_checkpoint/_target_:
  desc: null
  value: pytorch_lightning.callbacks.ModelCheckpoint
callbacks/model_checkpoint/filename:
  desc: null
  value: step_{step}
callbacks/model_checkpoint/save_last:
  desc: null
  value: true
model/config/reorder_and_upcast_attn:
  desc: null
  value: false
callbacks/loss_scale_monitor/_target_:
  desc: null
  value: train.callbacks.loss_scale_monitor.LossScaleMonitor
callbacks/model_checkpoint/save_top_k:
  desc: null
  value: 1
callbacks/params_log/total_params_log:
  desc: null
  value: true
callbacks/rich_model_summary/_target_:
  desc: null
  value: pytorch_lightning.callbacks.RichModelSummary
callbacks/speed_monitor/inter_step_time:
  desc: null
  value: true
callbacks/speed_monitor/intra_step_time:
  desc: null
  value: true
callbacks/learning_rate_monitor/_target_:
  desc: null
  value: pytorch_lightning.callbacks.LearningRateMonitor
callbacks/params_log/trainable_params_log:
  desc: null
  value: true
callbacks/model_checkpoint_progress/dirpath:
  desc: null
  value: /home/rahul/simran/based/train/checkpoints/10-20-attn=tk-repo=2-n=768-model=gpt2-small-pin=F-sync-F-v3
callbacks/model_checkpoint_progress/_target_:
  desc: null
  value: train.callbacks.model_checkpoint.ModelCheckpointMine
callbacks/model_checkpoint_progress/filename:
  desc: null
  value: progress_step_{step}
model/config/scale_attn_by_inverse_layer_idx:
  desc: null
  value: true
callbacks/model_checkpoint_progress/save_last:
  desc: null
  value: false
callbacks/params_log/non_trainable_params_log:
  desc: null
  value: true
callbacks/model_checkpoint/every_n_train_steps:
  desc: null
  value: 1000
callbacks/model_checkpoint_progress/save_top_k:
  desc: null
  value: -1
callbacks/learning_rate_monitor/logging_interval:
  desc: null
  value: step
train/optimizer_param_grouping/bias_weight_decay:
  desc: null
  value: false
callbacks/model_checkpoint/auto_insert_metric_name:
  desc: null
  value: false
callbacks/model_checkpoint_progress/fault_tolerant:
  desc: null
  value: true
callbacks/model_checkpoint_progress/every_n_train_steps:
  desc: null
  value: 50000
train/optimizer_param_grouping/normalization_weight_decay:
  desc: null
  value: false
callbacks/model_checkpoint_progress/auto_insert_metric_name:
  desc: null
  value: false
