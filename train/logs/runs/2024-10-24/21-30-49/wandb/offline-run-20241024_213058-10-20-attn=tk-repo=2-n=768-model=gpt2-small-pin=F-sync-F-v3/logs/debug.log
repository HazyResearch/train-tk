2024-10-24 21:30:58,382 INFO    MainThread:2394300 [wandb_setup.py:_flush():76] Current SDK version is 0.16.2
2024-10-24 21:30:58,382 INFO    MainThread:2394300 [wandb_setup.py:_flush():76] Configure stats pid to 2394300
2024-10-24 21:30:58,382 INFO    MainThread:2394300 [wandb_setup.py:_flush():76] Loading settings from /home/rahul/.config/wandb/settings
2024-10-24 21:30:58,382 INFO    MainThread:2394300 [wandb_setup.py:_flush():76] Loading settings from /home/rahul/simran/based/train/logs/runs/2024-10-24/21-30-49/wandb/settings
2024-10-24 21:30:58,382 INFO    MainThread:2394300 [wandb_setup.py:_flush():76] Loading settings from environment variables: {}
2024-10-24 21:30:58,382 INFO    MainThread:2394300 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2024-10-24 21:30:58,383 INFO    MainThread:2394300 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': 'train/run.py', 'program_abspath': '/home/rahul/simran/based/train/run.py', 'program': '/home/rahul/simran/based/train/run.py'}
2024-10-24 21:30:58,383 INFO    MainThread:2394300 [wandb_init.py:_log_setup():526] Logging user logs to ./wandb/offline-run-20241024_213058-10-20-attn=tk-repo=2-n=768-model=gpt2-small-pin=F-sync-F-v3/logs/debug.log
2024-10-24 21:30:58,383 INFO    MainThread:2394300 [wandb_init.py:_log_setup():527] Logging internal logs to ./wandb/offline-run-20241024_213058-10-20-attn=tk-repo=2-n=768-model=gpt2-small-pin=F-sync-F-v3/logs/debug-internal.log
2024-10-24 21:30:58,383 INFO    MainThread:2394300 [wandb_init.py:init():566] calling init triggers
2024-10-24 21:30:58,383 INFO    MainThread:2394300 [wandb_init.py:init():573] wandb.init called with sweep_config: {}
config: {}
2024-10-24 21:30:58,383 INFO    MainThread:2394300 [wandb_init.py:init():616] starting backend
2024-10-24 21:30:58,383 INFO    MainThread:2394300 [wandb_init.py:init():620] setting up manager
2024-10-24 21:30:58,384 INFO    MainThread:2394300 [backend.py:_multiprocessing_setup():105] multiprocessing start_methods=fork,spawn,forkserver, using: spawn
2024-10-24 21:30:58,386 INFO    MainThread:2394300 [wandb_init.py:init():628] backend started and connected
2024-10-24 21:30:58,388 INFO    MainThread:2394300 [wandb_init.py:init():720] updated telemetry
2024-10-24 21:30:58,397 INFO    MainThread:2394300 [wandb_init.py:init():753] communicating run to backend with 90.0 second timeout
2024-10-24 21:30:58,400 INFO    MainThread:2394300 [wandb_init.py:init():804] starting run threads in backend
2024-10-24 21:30:58,572 INFO    MainThread:2394300 [wandb_run.py:_console_start():2233] atexit reg
2024-10-24 21:30:58,572 INFO    MainThread:2394300 [wandb_run.py:_redirect():2088] redirect: wrap_raw
2024-10-24 21:30:58,574 INFO    MainThread:2394300 [wandb_run.py:_redirect():2153] Wrapping output streams.
2024-10-24 21:30:58,574 INFO    MainThread:2394300 [wandb_run.py:_redirect():2178] Redirects installed.
2024-10-24 21:30:58,574 INFO    MainThread:2394300 [wandb_init.py:init():847] run started, returning control to user process
2024-10-24 21:30:59,555 INFO    MainThread:2394300 [wandb_run.py:_config_callback():1342] config_cb None None {'model/params_total': 124255488, 'model/params_trainable': 124255488, 'model/params_not_trainable': 0}
2024-10-24 21:30:59,564 INFO    MainThread:2394300 [wandb_run.py:_config_callback():1342] config_cb None None {'work_dir': '/home/rahul/simran/based/train', 'data_dir': '/home/rahul/simran/based/train/data/', 'print_config': True, 'ignore_warnings': True, 'test_after_training': True, 'resume': False, 'seed': 1111, 'name': '10-20-attn=tk-repo=2-n=768-model=gpt2-small-pin=F-sync-F-v3', 'trainer/_target_': 'pytorch_lightning.Trainer', 'trainer/accelerator': 'gpu', 'trainer/min_epochs': 1, 'trainer/max_epochs': 1000, 'trainer/devices': 1, 'trainer/num_nodes': 1, 'trainer/accumulate_grad_batches': 64, 'trainer/max_steps': 400000, 'trainer/val_check_interval': 64000, 'trainer/check_val_every_n_epoch': None, 'trainer/precision': 16, 'trainer/gradient_clip_val': 1.0, 'trainer/strategy': None, 'train/optimizer/_target_': 'torch.optim.AdamW', 'train/optimizer/lr': 0.00015, 'train/optimizer/weight_decay': 0.1, 'train/scheduler/_target_': 'transformers.get_linear_schedule_with_warmup', 'train/scheduler/num_warmup_steps': 4000.0, 'train/scheduler/num_training_steps': 400000, 'train/gpu_mem': 82, 'train/global_batch_size': 512, 'train/optimizer_param_grouping/bias_weight_decay': False, 'train/optimizer_param_grouping/normalization_weight_decay': False, 'train/loss_fn/_target_': 'flash_attn.losses.cross_entropy.CrossEntropyLoss', 'train/loss_fn/inplace_backward': True, 'task/_target_': 'train.tasks.seq.SequenceLMModel', 'model/_target_': 'tktrainer.models.gpt.GPTLMHeadModel', 'model/_recursive_': True, 'model/config/_target_': 'transformers.GPT2Config', 'model/config/reorder_and_upcast_attn': False, 'model/config/scale_attn_by_inverse_layer_idx': True, 'model/config/n_positions': 768, 'model/config/n_embd': 768, 'model/config/n_head': 12, 'model/config/n_layer': 12, 'model/config/mha_type': 'tk', 'datamodule/_target_': 'train.datamodules.language_modeling_hf.LMDataModule', 'datamodule/dataset_name': 'openwebtext', 'datamodule/dataset_config_name': None, 'datamodule/tokenizer_name': 'gpt2', 'datamodule/cache_dir': '/scratch/openwebtext/cache', 'datamodule/max_length': 768, 'datamodule/val_ratio': 0.0005, 'datamodule/val_split_seed': 2357, 'datamodule/add_eos': True, 'datamodule/batch_size': 8, 'datamodule/batch_size_eval': 8, 'datamodule/num_workers': 32, 'datamodule/shuffle': True, 'datamodule/pin_memory': True, 'datamodule/fault_tolerant': True, 'datamodule/ddp': False, 'callbacks/rich_model_summary/_target_': 'pytorch_lightning.callbacks.RichModelSummary', 'callbacks/model_checkpoint/_target_': 'pytorch_lightning.callbacks.ModelCheckpoint', 'callbacks/model_checkpoint/monitor': 'val/loss', 'callbacks/model_checkpoint/mode': 'min', 'callbacks/model_checkpoint/save_top_k': 1, 'callbacks/model_checkpoint/save_last': True, 'callbacks/model_checkpoint/verbose': False, 'callbacks/model_checkpoint/dirpath': '/home/rahul/simran/based/train/checkpoints/10-20-attn=tk-repo=2-n=768-model=gpt2-small-pin=F-sync-F-v3', 'callbacks/model_checkpoint/filename': 'step_{step}', 'callbacks/model_checkpoint/auto_insert_metric_name': False, 'callbacks/model_checkpoint/every_n_train_steps': 1000, 'callbacks/early_stopping': None, 'callbacks/learning_rate_monitor/_target_': 'pytorch_lightning.callbacks.LearningRateMonitor', 'callbacks/learning_rate_monitor/logging_interval': 'step', 'callbacks/speed_monitor/_target_': 'train.callbacks.speed_monitor.SpeedMonitor', 'callbacks/speed_monitor/intra_step_time': True, 'callbacks/speed_monitor/inter_step_time': True, 'callbacks/speed_monitor/epoch_time': True, 'callbacks/loss_scale_monitor/_target_': 'train.callbacks.loss_scale_monitor.LossScaleMonitor', 'callbacks/params_log/_target_': 'train.callbacks.params_log.ParamsLog', 'callbacks/params_log/total_params_log': True, 'callbacks/params_log/trainable_params_log': True, 'callbacks/params_log/non_trainable_params_log': True, 'callbacks/gpu_affinity/_target_': 'train.callbacks.gpu_affinity.GpuAffinity', 'callbacks/norm_monitor/_target_': 'train.callbacks.norm_monitor.NormMonitor', 'callbacks/model_checkpoint_progress/_target_': 'train.callbacks.model_checkpoint.ModelCheckpointMine', 'callbacks/model_checkpoint_progress/fault_tolerant': True, 'callbacks/model_checkpoint_progress/every_n_train_steps': 50000, 'callbacks/model_checkpoint_progress/save_last': False, 'callbacks/model_checkpoint_progress/save_top_k': -1, 'callbacks/model_checkpoint_progress/dirpath': '/home/rahul/simran/based/train/checkpoints/10-20-attn=tk-repo=2-n=768-model=gpt2-small-pin=F-sync-F-v3', 'callbacks/model_checkpoint_progress/filename': 'progress_step_{step}', 'callbacks/model_checkpoint_progress/auto_insert_metric_name': False, 'eval/metrics/ppl/_target_': 'train.metrics.perplexity.Perplexity', 'eval/metrics/num-tokens/_target_': 'train.metrics.num_tokens.NumTokens', 'eval/log_on_step': True, 'logger/wandb/_target_': 'pytorch_lightning.loggers.wandb.WandbLogger', 'logger/wandb/project': 'based', 'logger/wandb/name': '10-20-attn=tk-repo=2-n=768-model=gpt2-small-pin=F-sync-F-v3', 'logger/wandb/save_dir': '.', 'logger/wandb/mode': 'offline', 'logger/wandb/id': '10-20-attn=tk-repo=2-n=768-model=gpt2-small-pin=F-sync-F-v3', 'logger/wandb/log_model': False, 'logger/wandb/prefix': '', 'logger/wandb/job_type': 'train', 'logger/wandb/group': '', 'logger/wandb/tags': [], 'default_mode': True, 'expt_name': '10-20-attn=tk-repo=2-n=768-model=gpt2-small-pin=F-sync-F-v3'}
