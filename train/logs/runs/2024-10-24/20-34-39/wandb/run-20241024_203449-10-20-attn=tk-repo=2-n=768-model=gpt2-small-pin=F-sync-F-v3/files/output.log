[[36m2024-10-24 20:34:49,537[39m][[34mtrain.training[39m][[32mINFO[39m] - Instantiating trainer <pytorch_lightning.Trainer>
[[36m2024-10-24 20:34:49,542[39m][[34mpytorch_lightning.utilities.rank_zero[39m][[32mINFO[39m] - Using 16bit native Automatic Mixed Precision (AMP)
[[36m2024-10-24 20:34:49,543[39m][[34mpytorch_lightning.utilities.rank_zero[39m][[32mINFO[39m] - Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.
[[36m2024-10-24 20:34:49,573[39m][[34mpytorch_lightning.utilities.rank_zero[39m][[32mINFO[39m] - GPU available: True (cuda), used: True
[[36m2024-10-24 20:34:49,619[39m][[34mpytorch_lightning.utilities.rank_zero[39m][[32mINFO[39m] - TPU available: False, using: 0 TPU cores
[[36m2024-10-24 20:34:49,619[39m][[34mpytorch_lightning.utilities.rank_zero[39m][[32mINFO[39m] - IPU available: False, using: 0 IPUs
[[36m2024-10-24 20:34:49,620[39m][[34mpytorch_lightning.utilities.rank_zero[39m][[32mINFO[39m] - HPU available: False, using: 0 HPUs
[[36m2024-10-24 20:34:49,621[39m][[34mtrain.training[39m][[32mINFO[39m] - Starting training!
[[36m2024-10-24 20:34:49,628[39m][[34mtrain.utils.utils[39m][[32mINFO[39m] - Load from cache at /scratch/openwebtext/cache/tokenizer_name-gpt2-val_ratio-0.0005-val_split_seed-2357-add_eos-True-detokenize-False
[[36m2024-10-24 20:34:49,834[39m][[34mtrain.utils.utils[39m][[32mINFO[39m] - Load from cache at /scratch/openwebtext/cache/tokenizer_name-gpt2-val_ratio-0.0005-val_split_seed-2357-add_eos-True-detokenize-False
[[36m2024-10-24 20:34:50,079[39m][[34mtrain.callbacks.gpu_affinity[39m][[32mINFO[39m] - 0: thread affinity: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11}
[[36m2024-10-24 20:34:50,371[39m][[34mpytorch_lightning.accelerators.cuda[39m][[32mINFO[39m] - LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [5]
Error executing job with overrides: ['experiment=tk/owt_tk_gpts', 'trainer.devices=1']
Traceback (most recent call last):
  File "/home/rahul/code/.venv/lib/python3.12/site-packages/hydra/_internal/utils.py", line 635, in _locate
    obj = import_module(part0)
          ^^^^^^^^^^^^^^^^^^^^
  File "/home/rahul/.local/share/uv/python/cpython-3.12.5-linux-x86_64-gnu/lib/python3.12/importlib/__init__.py", line 90, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1324, in _find_and_load_unlocked
ModuleNotFoundError: No module named 'apex'
The above exception was the direct cause of the following exception:
Traceback (most recent call last):
  File "/home/rahul/code/.venv/lib/python3.12/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 134, in _resolve_target
    target = _locate(target)
             ^^^^^^^^^^^^^^^
  File "/home/rahul/code/.venv/lib/python3.12/site-packages/hydra/_internal/utils.py", line 637, in _locate
    raise ImportError(
ImportError: Error loading 'apex.optimizers.FusedAdam':
ModuleNotFoundError("No module named 'apex'")
Are you sure that module 'apex' is installed?
The above exception was the direct cause of the following exception:
Traceback (most recent call last):
  File "/home/rahul/code/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 38, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rahul/code/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 645, in _fit_impl
    self._run(model, ckpt_path=self.ckpt_path)
  File "/home/rahul/code/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1079, in _run
    self.strategy.setup(self)
  File "/home/rahul/code/.venv/lib/python3.12/site-packages/pytorch_lightning/strategies/single_device.py", line 74, in setup
    super().setup(trainer)
  File "/home/rahul/code/.venv/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 154, in setup
    self.setup_optimizers(trainer)
  File "/home/rahul/code/.venv/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 142, in setup_optimizers
    self.optimizers, self.lr_scheduler_configs, self.optimizer_frequencies = _init_optimizers_and_lr_schedulers(
                                                                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rahul/code/.venv/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py", line 180, in _init_optimizers_and_lr_schedulers
    optim_conf = model.trainer._call_lightning_module_hook("configure_optimizers", pl_module=model)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rahul/code/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1342, in _call_lightning_module_hook
    output = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/rahul/simran/based/train/tasks/seq.py", line 141, in configure_optimizers
    optimizer = hydra.utils.instantiate(self.cfg.train.optimizer, parameters)
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rahul/code/.venv/lib/python3.12/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 226, in instantiate
    return instantiate_node(
           ^^^^^^^^^^^^^^^^^
  File "/home/rahul/code/.venv/lib/python3.12/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 333, in instantiate_node
    _target_ = _resolve_target(node.get(_Keys.TARGET), full_key)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rahul/code/.venv/lib/python3.12/site-packages/hydra/_internal/instantiate/_instantiate2.py", line 139, in _resolve_target
    raise InstantiationException(msg) from e
hydra.errors.InstantiationException: Error locating target 'apex.optimizers.FusedAdam', set env var HYDRA_FULL_ERROR=1 to see chained exception.
full_key: cfg.train.optimizer
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File "/home/rahul/simran/based/train/run.py", line 69, in <module>
    main()
  File "/home/rahul/code/.venv/lib/python3.12/site-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
  File "/home/rahul/code/.venv/lib/python3.12/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
  File "/home/rahul/code/.venv/lib/python3.12/site-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
  File "/home/rahul/code/.venv/lib/python3.12/site-packages/hydra/_internal/utils.py", line 223, in run_and_report
    raise ex
  File "/home/rahul/code/.venv/lib/python3.12/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
           ^^^^^^
  File "/home/rahul/code/.venv/lib/python3.12/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
            ^^^^^^^^^^
  File "/home/rahul/code/.venv/lib/python3.12/site-packages/hydra/_internal/hydra.py", line 132, in run
    _ = ret.return_value
        ^^^^^^^^^^^^^^^^
  File "/home/rahul/code/.venv/lib/python3.12/site-packages/hydra/core/utils.py", line 260, in return_value
    raise self._return_value
  File "/home/rahul/code/.venv/lib/python3.12/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
                       ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/rahul/simran/based/train/run.py", line 63, in main
    return train(config)
           ^^^^^^^^^^^^^
  File "/home/rahul/simran/based/train/training.py", line 187, in train
    trainer.fit(model=model, datamodule=datamodule, **ckpt_cfg)
  File "/home/rahul/code/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 603, in fit
    call._call_and_handle_interrupt(
  File "/home/rahul/code/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py", line 60, in _call_and_handle_interrupt
    trainer._call_callback_hooks("on_exception", exception)
  File "/home/rahul/code/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1380, in _call_callback_hooks
    fn(self, self.lightning_module, *args, **kwargs)
  File "/home/rahul/simran/based/train/callbacks/model_checkpoint.py", line 17, in on_exception
    trainer.save_checkpoint(str(Path(self.dirpath) / '.pl_auto_save.ckpt'))
  File "/home/rahul/code/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py", line 1941, in save_checkpoint
    self._checkpoint_connector.save_checkpoint(filepath, weights_only=weights_only, storage_options=storage_options)
  File "/home/rahul/code/.venv/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py", line 540, in save_checkpoint
    self.trainer.strategy.save_checkpoint(_checkpoint, filepath, storage_options=storage_options)
  File "/home/rahul/code/.venv/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py", line 466, in save_checkpoint
    self.checkpoint_io.save_checkpoint(checkpoint, filepath, storage_options=storage_options)
  File "/home/rahul/code/.venv/lib/python3.12/site-packages/lightning_lite/plugins/io/torch_io.py", line 54, in save_checkpoint
    _atomic_save(checkpoint, path)
  File "/home/rahul/code/.venv/lib/python3.12/site-packages/lightning_lite/utilities/cloud_io.py", line 69, in _atomic_save
    f.write(bytesbuffer.getvalue())
  File "/home/rahul/code/.venv/lib/python3.12/site-packages/fsspec/implementations/local.py", line 369, in write
    return self.f.write(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
OSError: [Errno 28] No space left on device